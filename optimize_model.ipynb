{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGBqst26QxJT",
    "outputId": "634e1ed4-1098-4cec-ad98-5f3e501ca8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting deap\n",
      "  Downloading deap-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 5.2 MB/s \n",
      "\u001b[?25hCollecting bitstring\n",
      "  Downloading bitstring-3.1.9-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
      "Installing collected packages: deap, bitstring\n",
      "Successfully installed bitstring-3.1.9 deap-1.3.3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "!pip install deap bitstring\n",
    "\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "from bitstring import BitArray\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "zUJN2YhXQxJk",
    "outputId": "da28bc16-2ea3-4a72-c70e-485149daf02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140,) (916,) (2140,) (916,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1146fb43-d175-4722-bee9-a17d04a83b69\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BORE_OIL_VOL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATEPRD</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-12</th>\n",
       "      <td>0.030164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-13</th>\n",
       "      <td>0.198133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-14</th>\n",
       "      <td>0.331061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-15</th>\n",
       "      <td>0.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-16</th>\n",
       "      <td>0.323400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1146fb43-d175-4722-bee9-a17d04a83b69')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1146fb43-d175-4722-bee9-a17d04a83b69 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1146fb43-d175-4722-bee9-a17d04a83b69');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            BORE_OIL_VOL\n",
       "DATEPRD                 \n",
       "2008-02-12      0.030164\n",
       "2008-02-13      0.198133\n",
       "2008-02-14      0.331061\n",
       "2008-02-15      0.276400\n",
       "2008-02-16      0.323400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"oil_data.csv\", index_col=\"DATEPRD\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled, index=df.index, columns=df.columns)\n",
    "\n",
    "date = df.index\n",
    "scaled_oil_data = scaled_df.BORE_OIL_VOL.to_numpy()\n",
    "\n",
    "split_date = 2140\n",
    "\n",
    "date_train = date[:split_date]\n",
    "date_test = date[split_date:]\n",
    "oil_train = scaled_oil_data[:split_date]\n",
    "oil_test = scaled_oil_data[split_date:]\n",
    "\n",
    "print(oil_train.shape, oil_test.shape, date_train.shape, date_test.shape)\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PWu7G3awQxJo"
   },
   "outputs": [],
   "source": [
    "def refresh():\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "class ResetStatesCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n",
    "\n",
    "def sequential_window_dataset(series, window_size):\n",
    "    \n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=window_size, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[1:]))\n",
    "    \n",
    "    return dataset.batch(1).prefetch(1)\n",
    "\n",
    "def train_model(train_dataset, validation_dataset, num_units):\n",
    "    model = Sequential([\n",
    "                    LSTM(num_units, return_sequences=True, stateful=True, batch_input_shape=[1, None, 1]),\n",
    "                    LSTM(num_units, return_sequences=True, stateful=True),\n",
    "                    Dense(1)\n",
    "            ])\n",
    "    optimizer = keras.optimizers.SGD(\n",
    "                    learning_rate=1e-3, \n",
    "                    momentum=0.9\n",
    "                )\n",
    "    model.compile(\n",
    "                    loss=keras.losses.Huber(), \n",
    "                    optimizer=optimizer, \n",
    "                    metrics=[\"mae\"]\n",
    "                )\n",
    "    reset_states = ResetStatesCallback()\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "                    \"LSTM_oil_checkpoint.h5\", \n",
    "                    save_best_only=True\n",
    "                    )\n",
    "    early_stopping = EarlyStopping(patience=50)\n",
    "    model.fit(\n",
    "                    train_dataset, \n",
    "                    epochs=100, \n",
    "                    verbose=0,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[\n",
    "                                early_stopping, \n",
    "                                model_checkpoint, \n",
    "                                reset_states\n",
    "                            ]\n",
    "            )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_evaluate(ga_individual_solution):   \n",
    "    # Decode GA solution to integer for window_size and num_units\n",
    "    window_size_bits = BitArray(ga_individual_solution[0:8])\n",
    "    num_units_bits = BitArray(ga_individual_solution[8:]) \n",
    "    window_size = window_size_bits.uint\n",
    "    num_units = num_units_bits.uint\n",
    "    print('\\nWindow Size: ', window_size, ', Num of Units: ', num_units)\n",
    "    \n",
    "    # Return fitness score of 100 if window_size or num_unit is zero\n",
    "    if window_size == 0 or num_units == 0:\n",
    "        return 100, \n",
    "    \n",
    "    # Segment the train_data based on new window_size; split into train and validation (80/20)\n",
    "    refresh()\n",
    "\n",
    "    oil_train_set = sequential_window_dataset(oil_train, window_size)\n",
    "    oil_test_set = sequential_window_dataset(oil_test, window_size)\n",
    "    \n",
    "    # Train LSTM model and predict on validation set\n",
    "    model = train_model(oil_train_set, oil_test_set, num_units)\n",
    "    \n",
    "    #load best model\n",
    "    model = keras.models.load_model(\"LSTM_oil_checkpoint.h5\")\n",
    "    LSTM_oil_forecast = model.predict(scaled_oil_data[np.newaxis, :, np.newaxis])\n",
    "    LSTM_oil_forecast = LSTM_oil_forecast[0, split_date - 1:-1, 0]\n",
    "\n",
    "    # # Calculate the RMSE score as fitness score for GA\n",
    "    mae = keras.metrics.mean_absolute_error(oil_test, LSTM_oil_forecast).numpy()\n",
    "    mse = keras.metrics.mean_squared_error(oil_test, LSTM_oil_forecast).numpy()\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    print(f'mae = {mae}, \\nmse = {mse}, \\nrmse = {rmse}')\n",
    "    \n",
    "    return rmse,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5gy73PrQxJu",
    "outputId": "c72803c0-96d9-4337-a04f-892e9ab9c5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window Size:  113 , Num of Units:  216\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "mae = 0.029531778767704964, \n",
      "mse = 0.002477714093402028, \n",
      "rmse = 0.049776642046265314\n",
      "\n",
      "Window Size:  72 , Num of Units:  90\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.02952352724969387, \n",
      "mse = 0.002524814335629344, \n",
      "rmse = 0.050247530642105624\n",
      "\n",
      "Window Size:  114 , Num of Units:  21\n",
      "1/1 [==============================] - 1s 988ms/step\n",
      "mae = 0.030123312026262283, \n",
      "mse = 0.0024029838386923075, \n",
      "rmse = 0.049020239072165975\n",
      "\n",
      "Window Size:  191 , Num of Units:  2\n",
      "1/1 [==============================] - 1s 979ms/step\n",
      "mae = 0.04529349505901337, \n",
      "mse = 0.0035201001446694136, \n",
      "rmse = 0.059330431859791935\n",
      "\n",
      "Window Size:  72 , Num of Units:  21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb06f9bccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.029806049540638924, \n",
      "mse = 0.002361022401601076, \n",
      "rmse = 0.048590352968475914\n",
      "\n",
      "Window Size:  114 , Num of Units:  90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb072084b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.03034490905702114, \n",
      "mse = 0.002609573770314455, \n",
      "rmse = 0.05108398741596485\n",
      "\n",
      "Window Size:  39 , Num of Units:  149\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.02687876485288143, \n",
      "mse = 0.0023031102027744055, \n",
      "rmse = 0.04799073038383981\n",
      "\n",
      "Window Size:  194 , Num of Units:  143\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.031386226415634155, \n",
      "mse = 0.0027124490588903427, \n",
      "rmse = 0.05208117758740045\n",
      "\n",
      "Window Size:  194 , Num of Units:  143\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.031386226415634155, \n",
      "mse = 0.0027124490588903427, \n",
      "rmse = 0.05208117758740045\n",
      "\n",
      "Window Size:  194 , Num of Units:  143\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.031386226415634155, \n",
      "mse = 0.0027124490588903427, \n",
      "rmse = 0.05208117758740045\n"
     ]
    }
   ],
   "source": [
    "population_size = 4\n",
    "num_generations = 4\n",
    "gene_length = 16\n",
    "\n",
    "# As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMax', base.Fitness, weights = (-1.0,))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', train_evaluate)\n",
    "\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, ngen = num_generations, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ogOtXxQxJx",
    "outputId": "06aaa31e-1911-4f7f-b87a-524a6a9dd4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Window Size:  194 , Num of Units:  143\n"
     ]
    }
   ],
   "source": [
    "best_individuals = tools.selBest(population,k = 1)\n",
    "best_window_size = None\n",
    "best_num_units = None\n",
    "\n",
    "for bi in best_individuals:\n",
    "    window_size_bits = BitArray(bi[0:8])\n",
    "    num_units_bits = BitArray(bi[8:]) \n",
    "    best_window_size = window_size_bits.uint\n",
    "    best_num_units = num_units_bits.uint\n",
    "    print('\\nWindow Size: ', best_window_size, ', Num of Units: ', best_num_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG9mkCXNQxJz",
    "outputId": "97e23d67-b188-4eac-dcbf-2abdf37a4603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "mae = 0.02981843613088131, \n",
      "mse = 0.0025387993082404137, \n",
      "rmse = 0.05038649926558119\n"
     ]
    }
   ],
   "source": [
    "refresh()\n",
    "\n",
    "oil_train_set = sequential_window_dataset(oil_train, best_window_size)\n",
    "oil_test_set = sequential_window_dataset(oil_test, best_window_size)\n",
    "\n",
    "model = Sequential([\n",
    "                    LSTM(best_num_units, return_sequences=True, stateful=True, batch_input_shape=[1, None, 1]),\n",
    "                    LSTM(best_num_units, return_sequences=True, stateful=True),\n",
    "                    Dense(1)\n",
    "            ])\n",
    "optimizer = keras.optimizers.SGD(\n",
    "                learning_rate=1e-3, \n",
    "                momentum=0.9\n",
    "            )\n",
    "model.compile(\n",
    "                loss=keras.losses.Huber(), \n",
    "                optimizer=optimizer, \n",
    "                metrics=[\"mae\"]\n",
    "            )\n",
    "reset_states = ResetStatesCallback()\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "                \"LSTM_oil_checkpoint.h5\", \n",
    "                save_best_only=True\n",
    "                )\n",
    "early_stopping = EarlyStopping(patience=50)\n",
    "model.fit(\n",
    "                oil_train_set, \n",
    "                epochs=500, \n",
    "                verbose=0,\n",
    "                validation_data=oil_test_set,\n",
    "                callbacks=[\n",
    "                            early_stopping, \n",
    "                            model_checkpoint, \n",
    "                            reset_states\n",
    "                        ]\n",
    "        )\n",
    "\n",
    "model = keras.models.load_model(\"LSTM_oil_checkpoint.h5\")\n",
    "LSTM_oil_forecast = model.predict(scaled_oil_data[np.newaxis, :, np.newaxis])\n",
    "LSTM_oil_forecast = LSTM_oil_forecast[0, split_date - 1:-1, 0]\n",
    "\n",
    "# # Calculate the RMSE score as fitness score for GA\n",
    "mae = keras.metrics.mean_absolute_error(oil_test, LSTM_oil_forecast).numpy()\n",
    "mse = keras.metrics.mean_squared_error(oil_test, LSTM_oil_forecast).numpy()\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print(f'mae = {mae}, \\nmse = {mse}, \\nrmse = {rmse}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "133444414d1ee3d5e92372fd828872450c43ed97795e9b0f6d2c2bdc325c8146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
